{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Batch Inferencing Service\n",
    "\n",
    "In previous labs, you used an Azure ML *pipeline* to automate the training and registration of a model, and you published a model as a web service for real-time *inferencing* (getting predictions from a model). Now you'll combine these two concepts to create a pipeline for *batch inferencing*. What does that mean? Well, imagine a health clinic takes patient measurements all day, saving the details for each patient in a separate file. Then overnight, the diabetes prediction model can be used to process all of the day's patient data as a batch, generating predictions that will be waiting the following morning so that the clinic can follow up with patients who are predicted to be at risk of diabetes. That's what you'll implement in this exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Your Workspace\n",
    "\n",
    "Now connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: You may be prompted to authenticate. Just copy the code and click the link provided to sign into your Azure subscription, and then return to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml import core, pipeline\n",
    "from azureml.pipeline import steps\n",
    "from azureml.core import compute, conda_dependencies, runconfig, authentication\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn import model_selection, tree, metrics\n",
    "import os\n",
    "import shutil\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.12.0 to work with workspace\n"
     ]
    }
   ],
   "source": [
    "ws = core.Workspace.from_config()\n",
    "print(f'Ready to use Azure ML {core.VERSION} to work with {ws.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Register a Model\n",
    "\n",
    "Now run the cell below to train and register a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: diabetes-training\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8893333333333333\n",
      "AUC: 0.8770884123588237\n",
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "experiment = core.Experiment(ws, 'diabetes-training')\n",
    "run = experiment.start_logging()\n",
    "print('Starting experiment:', experiment.name)\n",
    "\n",
    "print('Loading Data...')\n",
    "diabetes: pd.DataFrame = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "X = diabetes[\n",
    "        [\n",
    "            'Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure',\n",
    "            'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree',\n",
    "            'Age'\n",
    "        ]\n",
    "    ].to_numpy()\n",
    "y = diabetes['Diabetic'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.30, random_state=0\n",
    ")\n",
    "\n",
    "print('Training a decision tree model')\n",
    "model = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', acc)\n",
    "\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = metrics.roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC:', auc)\n",
    "run.log('AUC', auc)\n",
    "\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(model, model_file)\n",
    "run.upload_file(f'outputs/{model_file}', model_file)\n",
    "\n",
    "run.complete()\n",
    "\n",
    "run.register_model(\n",
    "    model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "    tags={'Training context':'Inline Training'},\n",
    "    properties={\n",
    "        'AUC': run.get_metrics()['AUC'], \n",
    "        'Accuracy': run.get_metrics()['Accuracy']\n",
    "    }\n",
    ")\n",
    "\n",
    "print('Model trained and registered.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Upload Batch Data\n",
    "\n",
    "Since we don't actually have a fully staffed clinic with patients from whom to get new data for this course, you'll generate a random sample from our diabetes CSV file and use those to test the pipeline. Then you'll upload that data to a datastore in the Azure Machine Learning workspace and register a dataset for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files...\n",
      "files saved!\n",
      "Uploading files to datastore...\n",
      "Uploading an estimated of 100 files\n",
      "Uploading batch-data/1.csv\n",
      "Uploading batch-data/10.csv\n",
      "Uploading batch-data/100.csv\n",
      "Uploading batch-data/11.csv\n",
      "Uploading batch-data/12.csv\n",
      "Uploading batch-data/13.csv\n",
      "Uploading batch-data/14.csv\n",
      "Uploading batch-data/15.csv\n",
      "Uploading batch-data/16.csv\n",
      "Uploading batch-data/17.csv\n",
      "Uploading batch-data/18.csv\n",
      "Uploading batch-data/19.csv\n",
      "Uploading batch-data/2.csv\n",
      "Uploading batch-data/20.csv\n",
      "Uploading batch-data/21.csv\n",
      "Uploading batch-data/22.csv\n",
      "Uploading batch-data/23.csv\n",
      "Uploading batch-data/24.csv\n",
      "Uploading batch-data/25.csv\n",
      "Uploading batch-data/26.csv\n",
      "Uploading batch-data/27.csv\n",
      "Uploading batch-data/28.csv\n",
      "Uploading batch-data/29.csv\n",
      "Uploading batch-data/3.csv\n",
      "Uploading batch-data/30.csv\n",
      "Uploading batch-data/31.csv\n",
      "Uploading batch-data/32.csv\n",
      "Uploading batch-data/33.csv\n",
      "Uploading batch-data/34.csv\n",
      "Uploading batch-data/35.csv\n",
      "Uploading batch-data/36.csv\n",
      "Uploading batch-data/37.csv\n",
      "Uploaded batch-data/27.csv, 1 files out of an estimated total of 100\n",
      "Uploading batch-data/38.csv\n",
      "Uploaded batch-data/21.csv, 2 files out of an estimated total of 100\n",
      "Uploading batch-data/39.csv\n",
      "Uploaded batch-data/1.csv, 3 files out of an estimated total of 100\n",
      "Uploading batch-data/4.csv\n",
      "Uploaded batch-data/16.csv, 4 files out of an estimated total of 100\n",
      "Uploading batch-data/40.csv\n",
      "Uploaded batch-data/31.csv, 5 files out of an estimated total of 100\n",
      "Uploading batch-data/41.csv\n",
      "Uploaded batch-data/36.csv, 6 files out of an estimated total of 100\n",
      "Uploading batch-data/42.csv\n",
      "Uploaded batch-data/20.csv, 7 files out of an estimated total of 100\n",
      "Uploading batch-data/43.csv\n",
      "Uploaded batch-data/38.csv, 8 files out of an estimated total of 100\n",
      "Uploaded batch-data/4.csv, 9 files out of an estimated total of 100\n",
      "Uploading batch-data/44.csv\n",
      "Uploading batch-data/45.csv\n",
      "Uploaded batch-data/22.csv, 10 files out of an estimated total of 100\n",
      "Uploading batch-data/46.csv\n",
      "Uploaded batch-data/39.csv, 11 files out of an estimated total of 100\n",
      "Uploading batch-data/47.csv\n",
      "Uploaded batch-data/41.csv, 12 files out of an estimated total of 100\n",
      "Uploading batch-data/48.csv\n",
      "Uploaded batch-data/44.csv, 13 files out of an estimated total of 100\n",
      "Uploading batch-data/49.csv\n",
      "Uploaded batch-data/40.csv, 14 files out of an estimated total of 100\n",
      "Uploading batch-data/5.csv\n",
      "Uploaded batch-data/18.csv, 15 files out of an estimated total of 100\n",
      "Uploading batch-data/50.csv\n",
      "Uploaded batch-data/42.csv, 16 files out of an estimated total of 100\n",
      "Uploaded batch-data/45.csv, 17 files out of an estimated total of 100\n",
      "Uploading batch-data/51.csv\n",
      "Uploading batch-data/52.csv\n",
      "Uploaded batch-data/46.csv, 18 files out of an estimated total of 100\n",
      "Uploading batch-data/53.csv\n",
      "Uploaded batch-data/24.csv, 19 files out of an estimated total of 100\n",
      "Uploading batch-data/54.csv\n",
      "Uploaded batch-data/33.csv, 20 files out of an estimated total of 100\n",
      "Uploading batch-data/55.csv\n",
      "Uploaded batch-data/100.csv, 21 files out of an estimated total of 100\n",
      "Uploading batch-data/56.csv\n",
      "Uploaded batch-data/26.csv, 22 files out of an estimated total of 100\n",
      "Uploading batch-data/57.csv\n",
      "Uploaded batch-data/43.csv, 23 files out of an estimated total of 100\n",
      "Uploading batch-data/58.csv\n",
      "Uploaded batch-data/23.csv, 24 files out of an estimated total of 100\n",
      "Uploading batch-data/59.csv\n",
      "Uploaded batch-data/34.csv, 25 files out of an estimated total of 100\n",
      "Uploading batch-data/6.csv\n",
      "Uploaded batch-data/12.csv, 26 files out of an estimated total of 100\n",
      "Uploading batch-data/60.csv\n",
      "Uploaded batch-data/50.csv, 27 files out of an estimated total of 100\n",
      "Uploading batch-data/61.csv\n",
      "Uploaded batch-data/10.csv, 28 files out of an estimated total of 100\n",
      "Uploaded batch-data/5.csv, 29 files out of an estimated total of 100\n",
      "Uploading batch-data/62.csv\n",
      "Uploaded batch-data/47.csv, 30 files out of an estimated total of 100\n",
      "Uploading batch-data/63.csv\n",
      "Uploaded batch-data/2.csv, 31 files out of an estimated total of 100\n",
      "Uploading batch-data/64.csv\n",
      "Uploaded batch-data/13.csv, 32 files out of an estimated total of 100\n",
      "Uploading batch-data/65.csv\n",
      "Uploaded batch-data/32.csv, 33 files out of an estimated total of 100\n",
      "Uploading batch-data/66.csv\n",
      "Uploaded batch-data/29.csv, 34 files out of an estimated total of 100\n",
      "Uploading batch-data/67.csv\n",
      "Uploaded batch-data/11.csv, 35 files out of an estimated total of 100\n",
      "Uploading batch-data/68.csv\n",
      "Uploading batch-data/69.csv\n",
      "Uploaded batch-data/49.csv, 36 files out of an estimated total of 100\n",
      "Uploaded batch-data/28.csv, 37 files out of an estimated total of 100\n",
      "Uploading batch-data/7.csv\n",
      "Uploaded batch-data/15.csv, 38 files out of an estimated total of 100\n",
      "Uploaded batch-data/51.csv, 39 files out of an estimated total of 100\n",
      "Uploading batch-data/70.csv\n",
      "Uploading batch-data/71.csv\n",
      "Uploaded batch-data/48.csv, 40 files out of an estimated total of 100\n",
      "Uploading batch-data/72.csv\n",
      "Uploaded batch-data/37.csv, 41 files out of an estimated total of 100\n",
      "Uploading batch-data/73.csv\n",
      "Uploaded batch-data/35.csv, 42 files out of an estimated total of 100\n",
      "Uploading batch-data/74.csv\n",
      "Uploaded batch-data/53.csv, 43 files out of an estimated total of 100\n",
      "Uploaded batch-data/17.csv, 44 files out of an estimated total of 100\n",
      "Uploading batch-data/75.csv\n",
      "Uploaded batch-data/3.csv, 45 files out of an estimated total of 100\n",
      "Uploading batch-data/76.csv\n",
      "Uploaded batch-data/54.csv, 46 files out of an estimated total of 100\n",
      "Uploading batch-data/77.csv\n",
      "Uploading batch-data/78.csv\n",
      "Uploaded batch-data/19.csv, 47 files out of an estimated total of 100\n",
      "Uploading batch-data/79.csv\n",
      "Uploaded batch-data/66.csv, 48 files out of an estimated total of 100\n",
      "Uploading batch-data/8.csv\n",
      "Uploaded batch-data/30.csv, 49 files out of an estimated total of 100\n",
      "Uploaded batch-data/58.csv, 50 files out of an estimated total of 100\n",
      "Uploading batch-data/80.csv\n",
      "Uploaded batch-data/6.csv, 51 files out of an estimated total of 100\n",
      "Uploading batch-data/81.csv\n",
      "Uploaded batch-data/14.csv, 52 files out of an estimated total of 100\n",
      "Uploading batch-data/82.csv\n",
      "Uploaded batch-data/25.csv, 53 files out of an estimated total of 100\n",
      "Uploading batch-data/83.csv\n",
      "Uploading batch-data/84.csv\n",
      "Uploaded batch-data/52.csv, 54 files out of an estimated total of 100\n",
      "Uploading batch-data/85.csv\n",
      "Uploaded batch-data/55.csv, 55 files out of an estimated total of 100\n",
      "Uploading batch-data/86.csv\n",
      "Uploaded batch-data/56.csv, 56 files out of an estimated total of 100\n",
      "Uploading batch-data/87.csv\n",
      "Uploading batch-data/88.csv\n",
      "Uploaded batch-data/60.csv, 57 files out of an estimated total of 100\n",
      "Uploading batch-data/89.csv\n",
      "Uploaded batch-data/59.csv, 58 files out of an estimated total of 100\n",
      "Uploading batch-data/9.csv\n",
      "Uploaded batch-data/57.csv, 59 files out of an estimated total of 100\n",
      "Uploading batch-data/90.csv\n",
      "Uploaded batch-data/74.csv, 60 files out of an estimated total of 100\n",
      "Uploading batch-data/91.csv\n",
      "Uploaded batch-data/73.csv, 61 files out of an estimated total of 100\n",
      "Uploading batch-data/92.csv\n",
      "Uploaded batch-data/61.csv, 62 files out of an estimated total of 100\n",
      "Uploading batch-data/93.csv\n",
      "Uploaded batch-data/65.csv, 63 files out of an estimated total of 100\n",
      "Uploading batch-data/94.csv\n",
      "Uploaded batch-data/69.csv, 64 files out of an estimated total of 100\n",
      "Uploading batch-data/95.csv\n",
      "Uploaded batch-data/63.csv, 65 files out of an estimated total of 100\n",
      "Uploaded batch-data/72.csv, 66 files out of an estimated total of 100\n",
      "Uploading batch-data/96.csv\n",
      "Uploaded batch-data/75.csv, 67 files out of an estimated total of 100\n",
      "Uploading batch-data/97.csv\n",
      "Uploaded batch-data/70.csv, 68 files out of an estimated total of 100\n",
      "Uploading batch-data/98.csv\n",
      "Uploading batch-data/99.csv\n",
      "Uploaded batch-data/62.csv, 69 files out of an estimated total of 100\n",
      "Uploaded batch-data/7.csv, 70 files out of an estimated total of 100\n",
      "Uploaded batch-data/64.csv, 71 files out of an estimated total of 100\n",
      "Uploaded batch-data/71.csv, 72 files out of an estimated total of 100\n",
      "Uploaded batch-data/81.csv, 73 files out of an estimated total of 100\n",
      "Uploaded batch-data/67.csv, 74 files out of an estimated total of 100\n",
      "Uploaded batch-data/78.csv, 75 files out of an estimated total of 100\n",
      "Uploaded batch-data/76.csv, 76 files out of an estimated total of 100\n",
      "Uploaded batch-data/80.csv, 77 files out of an estimated total of 100\n",
      "Uploaded batch-data/82.csv, 78 files out of an estimated total of 100\n",
      "Uploaded batch-data/68.csv, 79 files out of an estimated total of 100\n",
      "Uploaded batch-data/91.csv, 80 files out of an estimated total of 100\n",
      "Uploaded batch-data/77.csv, 81 files out of an estimated total of 100\n",
      "Uploaded batch-data/9.csv, 82 files out of an estimated total of 100\n",
      "Uploaded batch-data/98.csv, 83 files out of an estimated total of 100\n",
      "Uploaded batch-data/88.csv, 84 files out of an estimated total of 100\n",
      "Uploaded batch-data/79.csv, 85 files out of an estimated total of 100\n",
      "Uploaded batch-data/84.csv, 86 files out of an estimated total of 100\n",
      "Uploaded batch-data/93.csv, 87 files out of an estimated total of 100\n",
      "Uploaded batch-data/8.csv, 88 files out of an estimated total of 100\n",
      "Uploaded batch-data/86.csv, 89 files out of an estimated total of 100\n",
      "Uploaded batch-data/85.csv, 90 files out of an estimated total of 100\n",
      "Uploaded batch-data/83.csv, 91 files out of an estimated total of 100\n",
      "Uploaded batch-data/95.csv, 92 files out of an estimated total of 100\n",
      "Uploaded batch-data/92.csv, 93 files out of an estimated total of 100\n",
      "Uploaded batch-data/96.csv, 94 files out of an estimated total of 100\n",
      "Uploaded batch-data/97.csv, 95 files out of an estimated total of 100\n",
      "Uploaded batch-data/94.csv, 96 files out of an estimated total of 100\n",
      "Uploaded batch-data/99.csv, 97 files out of an estimated total of 100\n",
      "Uploaded batch-data/87.csv, 98 files out of an estimated total of 100\n",
      "Uploaded batch-data/89.csv, 99 files out of an estimated total of 100\n",
      "Uploaded batch-data/90.csv, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "diabetes = pd.read_csv('data/diabetes2.csv')\n",
    "sample = diabetes[\n",
    "    [\n",
    "        'Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure',\n",
    "        'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree',\n",
    "        'Age'\n",
    "    ]\n",
    "].sample(n=100).to_numpy()\n",
    "\n",
    "batch_folder = './batch-data'\n",
    "\n",
    "print('Saving files...')\n",
    "for i in range(100):\n",
    "    file_name = str(i+1) + '.csv'\n",
    "    sample[i].tofile(os.path.join(batch_folder, file_name), sep=',')\n",
    "print('files saved!')\n",
    "\n",
    "print('Uploading files to datastore...')\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload(\n",
    "    src_dir='batch-data', target_path='batch-data', overwrite=True,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "batch_data_set = core.Dataset.File.from_files((default_ds, 'batch-data/'))\n",
    "batch_data_set = batch_data_set.register(\n",
    "    workspace=ws,\n",
    "    name='batch-data',\n",
    "    description='batch data',\n",
    "    create_new_version=True\n",
    ")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Compute\n",
    "\n",
    "We'll need a compute context for the pipeline, so we'll create an Azure Machine Learning compute cluster in your workspace (or use an existing one if you have created it previously).\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to the unique name for your compute cluster in the code below before running it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "cluster_name = \"susumu-cluster\"\n",
    "\n",
    "inference_cluster = compute.ComputeTarget(ws, cluster_name)\n",
    "print('Found existing cluster, use it.')\n",
    "\n",
    "inference_cluster.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Pipeline for Batch Inferencing\n",
    "\n",
    "Next we'll define a run context that includes the dependencies required by the script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "cd = conda_dependencies.CondaDependencies.create(\n",
    "    pip_packages=[\n",
    "        'scikit-learn', 'azureml-defaults', 'azureml-core',\n",
    "        'azureml-dataprep[fuse]',\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_env = core.Environment('batch_environment')\n",
    "batch_env.python.conda_dependencies = cd\n",
    "batch_env.docker.enabled = True\n",
    "batch_env.docker.base_image = runconfig.DEFAULT_CPU_IMAGE\n",
    "print('Configuration ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a **ParallelRunStep**, which enables the batch data to be processed in parallel and the results collated in a single output file named *parallel_run_step.txt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps defined\n"
     ]
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "output_dir = pipeline.core.PipelineData(\n",
    "    'inferences',\n",
    "    datastore=default_ds,\n",
    "    output_path_on_compute='diabetes/results'\n",
    ")\n",
    "\n",
    "experiment_folder = 'batch-pipeline'\n",
    "parallel_run_config = steps.ParallelRunConfig(\n",
    "    environment=batch_env,\n",
    "    entry_script='batch_diabetes.py',\n",
    "    error_threshold=10,\n",
    "    output_action='append_row',\n",
    "    compute_target=inference_cluster,\n",
    "    node_count=1,\n",
    "    source_directory=experiment_folder,\n",
    ")\n",
    "\n",
    "parallel_run_step = steps.ParallelRunStep(\n",
    "    'batch-score-diabetes',\n",
    "    parallel_run_config,\n",
    "    [batch_data_set.as_named_input('diabetes_batch')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    ")\n",
    "\n",
    "print('Steps defined')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to put the step into a pipeline, and run it.\n",
    "\n",
    "> **Note**: This may take some time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch-score-diabetes [675c03cc][3d93909b-34e6-44f1-8447-e3da061d573f], (This step will run and generate new outputs)\n",
      "Created data reference diabetes_batch_0 for StepId [39cc58fa][ee94ac98-61e2-4067-b87f-c8564f9c0b9a], (Consumers of this data will generate new runs.)\n",
      "Submitted PipelineRun 35a034bd-1ec8-41de-9f4b-fb8cdc067bc0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_prediction_pipeline/runs/35a034bd-1ec8-41de-9f4b-fb8cdc067bc0?wsid=/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourcegroups/resources/workspaces/workspace\n",
      "Running pipeline...\n",
      "PipelineRunId: 35a034bd-1ec8-41de-9f4b-fb8cdc067bc0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_prediction_pipeline/runs/35a034bd-1ec8-41de-9f4b-fb8cdc067bc0?wsid=/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourcegroups/resources/workspaces/workspace\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 50eb4267-4f7b-415f-9a22-dea8aab740cd\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/batch_prediction_pipeline/runs/50eb4267-4f7b-415f-9a22-dea8aab740cd?wsid=/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourcegroups/resources/workspaces/workspace\n",
      "StepRun( batch-score-diabetes ) Status: NotStarted\n",
      "StepRun( batch-score-diabetes ) Status: Queued\n",
      "StepRun( batch-score-diabetes ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/08/17 21:44:59 Downloading source code...\n",
      "2020/08/17 21:45:00 Finished downloading source code\n",
      "2020/08/17 21:45:01 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/08/17 21:45:01 Successfully set up Docker network: acb_default_network\n",
      "2020/08/17 21:45:01 Setting up Docker configuration...\n",
      "2020/08/17 21:45:02 Successfully set up Docker configuration\n",
      "2020/08/17 21:45:02 Logging in to registry: 9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io\n",
      "2020/08/17 21:45:03 Successfully logged into 9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io\n",
      "2020/08/17 21:45:03 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/08/17 21:45:03 Scanning for dependencies...\n",
      "2020/08/17 21:45:04 Successfully scanned dependencies\n",
      "2020/08/17 21:45:04 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200723.v1@sha256:6446903197a22de6711cbbf07f047b351d84d3ec9f3cab62f6312433461e5608\n",
      "sha256:6446903197a22de6711cbbf07f047b351d84d3ec9f3cab62f6312433461e5608: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "6aa38bd67045: Already exists\n",
      "981ae4862c05: Already exists\n",
      "5bad8949dcb1: Already exists\n",
      "ca9461589e70: Already exists\n",
      "98d7f5a52dc7: Pulling fs layer\n",
      "55bd0fd3d326: Pulling fs layer\n",
      "c701d81a8c64: Pulling fs layer\n",
      "377536e3f3d3: Pulling fs layer\n",
      "be7af55ccd20: Pulling fs layer\n",
      "527ddc9414f3: Pulling fs layer\n",
      "67e3aa572370: Pulling fs layer\n",
      "41d293c79c2d: Pulling fs layer\n",
      "377536e3f3d3: Waiting\n",
      "be7af55ccd20: Waiting\n",
      "527ddc9414f3: Waiting\n",
      "67e3aa572370: Waiting\n",
      "41d293c79c2d: Waiting\n",
      "55bd0fd3d326: Verifying Checksum\n",
      "55bd0fd3d326: Download complete\n",
      "c701d81a8c64: Verifying Checksum\n",
      "c701d81a8c64: Download complete\n",
      "98d7f5a52dc7: Verifying Checksum\n",
      "98d7f5a52dc7: Download complete\n",
      "377536e3f3d3: Verifying Checksum\n",
      "377536e3f3d3: Download complete\n",
      "527ddc9414f3: Verifying Checksum\n",
      "527ddc9414f3: Download complete\n",
      "be7af55ccd20: Verifying Checksum\n",
      "be7af55ccd20: Download complete\n",
      "67e3aa572370: Verifying Checksum\n",
      "67e3aa572370: Download complete\n",
      "41d293c79c2d: Download complete\n",
      "98d7f5a52dc7: Pull complete\n",
      "55bd0fd3d326: Pull complete\n",
      "c701d81a8c64: Pull complete\n",
      "377536e3f3d3: Pull complete\n",
      "be7af55ccd20: Pull complete\n",
      "527ddc9414f3: Pull complete\n",
      "67e3aa572370: Pull complete\n",
      "41d293c79c2d: Pull complete\n",
      "Digest: sha256:6446903197a22de6711cbbf07f047b351d84d3ec9f3cab62f6312433461e5608\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200723.v1@sha256:6446903197a22de6711cbbf07f047b351d84d3ec9f3cab62f6312433461e5608\n",
      " ---> 6c431041858f\n",
      "Step 2/15 : USER root\n",
      " ---> Running in c83290c7776e\n",
      "Removing intermediate container c83290c7776e\n",
      " ---> 94b6af099197\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 3612bd56109a\n",
      "Removing intermediate container 3612bd56109a\n",
      " ---> 807e8229baad\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in aa589e478117\n",
      "Removing intermediate container aa589e478117\n",
      " ---> dc216065f487\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 329aea902b6d\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 82ccc5394380\n",
      "Removing intermediate container 82ccc5394380\n",
      " ---> 2d462bb42e4e\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> e7dd44e05401\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_0d2c44fcbf994b7e881cd6e7891c081c -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 3eee31e91a1f\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "wheel-0.34.2         | 49 KB     |            |   0% \n",
      "wheel-0.34.2         | 49 KB     | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "pip-20.2.2           | 2.0 MB    |            |   0% \n",
      "pip-20.2.2           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \n",
      "\n",
      "setuptools-49.6.0    | 927 KB    |            |   0% \n",
      "setuptools-49.6.0    | 927 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 133 KB    |            |   0% \n",
      "ca-certificates-2020 | 133 KB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | #9         |  20% \n",
      "python-3.6.2         | 27.0 MB   | #####3     |  53% \n",
      "python-3.6.2         | 27.0 MB   | ########5  |  86% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ######4    |  64% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_0d2c44fcbf994b7e881cd6e7891c081c/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.z0rpt351.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.12.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting azureml-core\n",
      "  Downloading azureml_core-1.12.0.post1-py3-none-any.whl (2.0 MB)\n",
      "Collecting azureml-dataprep[fuse]\n",
      "  Downloading azureml_dataprep-2.0.6-py3-none-any.whl (28.2 MB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting numpy>=1.13.3\n",
      "  Downloading numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting werkzeug==0.16.1\n",
      "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.12.0\n",
      "  Downloading azureml_dataset_runtime-1.12.0-py3-none-any.whl (3.2 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-3.0-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1\n",
      "  Downloading azure_mgmt_resource-10.2.0-py2.py3-none-any.whl (968 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting ruamel.yaml>=0.15.35\n",
      "  Downloading ruamel.yaml-0.16.10-py2.py3-none-any.whl (111 kB)\n",
      "Collecting azure-graphrbac>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.18-py2.py3-none-any.whl (84 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.3.0-py2.py3-none-any.whl (145 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting requests>=2.19.1\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting azure-mgmt-storage>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.1.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-identity<1.3.0,>=1.2.0\n",
      "  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.14-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting azureml-dataprep-native<21.0.0,>=20.0.2\n",
      "  Downloading azureml_dataprep_native-20.0.2-cp36-cp36m-manylinux1_x86_64.whl (10.7 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.5.0-py3-none-any.whl (22 kB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.4.0.tar.gz (15 kB)\n",
      "Collecting pandas>=0.20.2\n",
      "  Downloading pandas-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (10.5 MB)\n",
      "Collecting six>=1.10\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.2.zip (177 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting pyarrow<2.0.0,>=0.17.0\n",
      "  Downloading pyarrow-1.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.2 MB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.2-cp36-cp36m-manylinux1_x86_64.whl (400 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
      "  Downloading ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_0d2c44fcbf994b7e881cd6e7891c081c/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core->-r /azureml-environment-setup/condaenv.z0rpt351.requirements.txt (line 3)) (2020.6.20)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.8.0-py2.py3-none-any.whl (121 kB)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Downloading msal-1.4.3-py2.py3-none-any.whl (49 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, liac-arff, dill\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=e75dccb4134b9636de0cd111ad0561834ef91698067316cf8ac80c1384624628\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=6fc85b1c840e8b41c25be673522f394fa00355091fbc92155bc5831a5bdc123f\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=bc3aa859c782f2c68f0d74e09b63d03dea2212a5d024e82184f4d707d90fab27\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=78912 sha256=09ab10ecdaf9eb950fb2107a52e37678621c103571a9c6f3b3c71fcbd9c78591\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/49/cf/660924cd9bc5fcddc3a0246fe39800c83028d3ccea244de352\n",
      "Successfully built json-logging-py fusepy liac-arff dill\n",
      "Installing collected packages: numpy, scipy, joblib, threadpoolctl, scikit-learn, configparser, werkzeug, json-logging-py, liac-arff, chardet, idna, urllib3, requests, pytz, six, python-dateutil, pandas, pycparser, cffi, cryptography, PyJWT, adal, dill, azureml-model-management-sdk, click, itsdangerous, MarkupSafe, Jinja2, flask, azure-common, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-mgmt-authorization, azure-mgmt-keyvault, contextlib2, azure-mgmt-resource, jeepney, SecretStorage, ruamel.yaml.clib, ruamel.yaml, azure-graphrbac, pathspec, azure-mgmt-containerregistry, pyopenssl, pyasn1, ndg-httpsclient, zipp, importlib-metadata, jsonpickle, backports.weakref, backports.tempfile, websocket-client, docker, azure-mgmt-storage, jmespath, azureml-core, applicationinsights, gunicorn, portalocker, msal, msal-extensions, azure-core, azure-identity, distro, dotnetcore2, azureml-dataprep-native, cloudpickle, fusepy, azureml-dataprep, pyarrow, azureml-dataset-runtime, azureml-defaults\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.4 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.8.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-10.2.0 azure-mgmt-storage-11.1.0 azureml-core-1.12.0.post1 azureml-dataprep-2.0.6 azureml-dataprep-native-20.0.2 azureml-dataset-runtime-1.12.0 azureml-defaults-1.12.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.2 chardet-3.0.4 click-7.1.2 cloudpickle-1.5.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.0 dill-0.3.2 distro-1.5.0 docker-4.3.0 dotnetcore2-2.1.14 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-1.7.0 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.10.0 joblib-0.16.0 json-logging-py-0.2 jsonpickle-1.4.1 liac-arff-2.4.0 msal-1.4.3 msal-extensions-0.1.3 msrest-0.6.18 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.1 oauthlib-3.1.0 pandas-1.1.0 pathspec-0.8.0 portalocker-1.7.1 pyarrow-1.0.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.1 requests-2.24.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 scikit-learn-0.23.2 scipy-1.5.2 six-1.15.0 threadpoolctl-2.1.0 urllib3-1.25.10 websocket-client-0.57.0 werkzeug-0.16.1 zipp-3.1.0\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.8.4\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_0d2c44fcbf994b7e881cd6e7891c081c\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 3eee31e91a1f\n",
      " ---> 96f8eb6f528c\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_0d2c44fcbf994b7e881cd6e7891c081c/bin:$PATH\n",
      " ---> Running in c93f37ea005c\n",
      "Removing intermediate container c93f37ea005c\n",
      " ---> 3313509563e8\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_0d2c44fcbf994b7e881cd6e7891c081c\n",
      " ---> Running in 2e92133ecde0\n",
      "Removing intermediate container 2e92133ecde0\n",
      " ---> cbc1061e62bd\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_0d2c44fcbf994b7e881cd6e7891c081c/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 6b8982634fe3\n",
      "Removing intermediate container 6b8982634fe3\n",
      " ---> e82c7b64844f\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 870ac719fd64\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in fc12db954322\n",
      "Removing intermediate container fc12db954322\n",
      " ---> 1ba786a9a10e\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 63e80f4029e7\n",
      "Removing intermediate container 63e80f4029e7\n",
      " ---> 51a0075be634\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in 29f873a89cbc\n",
      "Removing intermediate container 29f873a89cbc\n",
      " ---> a4858a23241e\n",
      "Successfully built a4858a23241e\n",
      "Successfully tagged 9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io/azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d:latest\n",
      "2020/08/17 21:47:50 Successfully executed container: acb_step_0\n",
      "2020/08/17 21:47:50 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/08/17 21:47:50 Pushing image: 9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io/azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d:latest, attempt 1\n",
      "The push refers to repository [9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io/azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d]\n",
      "5e3e3bd8808c: Preparing\n",
      "8b9f21bdc5d2: Preparing\n",
      "d5d9ae21711d: Preparing\n",
      "28d1b57a4d30: Preparing\n",
      "eb46ffa9ae0b: Preparing\n",
      "359937a07d0e: Preparing\n",
      "ca4051980d49: Preparing\n",
      "8445967f3cd7: Preparing\n",
      "5b3957211d87: Preparing\n",
      "5a68d248281a: Preparing\n",
      "7bf666214bc3: Preparing\n",
      "390b01cda284: Preparing\n",
      "59fc75f21a74: Preparing\n",
      "64c3df0bcd5e: Preparing\n",
      "377c01c3f4e3: Preparing\n",
      "968d3b985bf4: Preparing\n",
      "631dfaad8559: Preparing\n",
      "d908d9ad6713: Preparing\n",
      "359937a07d0e: Waiting\n",
      "ca4051980d49: Waiting\n",
      "8445967f3cd7: Waiting\n",
      "5b3957211d87: Waiting\n",
      "5a68d248281a: Waiting\n",
      "7bf666214bc3: Waiting\n",
      "390b01cda284: Waiting\n",
      "59fc75f21a74: Waiting\n",
      "64c3df0bcd5e: Waiting\n",
      "377c01c3f4e3: Waiting\n",
      "968d3b985bf4: Waiting\n",
      "631dfaad8559: Waiting\n",
      "d908d9ad6713: Waiting\n",
      "eb46ffa9ae0b: Pushed\n",
      "d5d9ae21711d: Pushed\n",
      "5e3e3bd8808c: Pushed\n",
      "28d1b57a4d30: Pushed\n",
      "359937a07d0e: Pushed\n",
      "ca4051980d49: Pushed\n",
      "8445967f3cd7: Pushed\n",
      "5b3957211d87: Pushed\n",
      "59fc75f21a74: Pushed\n",
      "7bf666214bc3: Pushed\n",
      "377c01c3f4e3: Pushed\n",
      "968d3b985bf4: Pushed\n",
      "390b01cda284: Pushed\n",
      "5a68d248281a: Pushed\n",
      "631dfaad8559: Pushed\n",
      "\n",
      "d908d9ad6713: Pushed\n",
      "64c3df0bcd5e: Pushed\n",
      "8b9f21bdc5d2: Pushed\n",
      "latest: digest: sha256:20355426e894145694dfc52c21ebe4b136985705d154d978616c44aa6a3b8e4d size: 4095\n",
      "2020/08/17 21:49:21 Successfully pushed image: 9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io/azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d:latest\n",
      "2020/08/17 21:49:21 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 167.482747)\n",
      "2020/08/17 21:49:21 Populating digests for step ID: acb_step_0...\n",
      "2020/08/17 21:49:23 Successfully populated digests for step ID: acb_step_0\n",
      "2020/08/17 21:49:23 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 90.932880)\n",
      "2020/08/17 21:49:23 The following dependencies were found:\n",
      "2020/08/17 21:49:23 \n",
      "- image:\n",
      "    registry: 9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io\n",
      "    repository: azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d\n",
      "    tag: latest\n",
      "    digest: sha256:20355426e894145694dfc52c21ebe4b136985705d154d978616c44aa6a3b8e4d\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20200723.v1\n",
      "    digest: sha256:6446903197a22de6711cbbf07f047b351d84d3ec9f3cab62f6312433461e5608\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cq4 was successful after 4m25s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt\n",
      "========================================================================================================================\n",
      "2020-08-17T21:54:12Z Starting output-watcher...\n",
      "2020-08-17T21:54:12Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-08-17T21:54:14Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-08-17T21:54:14Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d\n",
      "6aa38bd67045: Pulling fs layer\n",
      "981ae4862c05: Pulling fs layer\n",
      "5bad8949dcb1: Pulling fs layer\n",
      "ca9461589e70: Pulling fs layer\n",
      "98d7f5a52dc7: Pulling fs layer\n",
      "55bd0fd3d326: Pulling fs layer\n",
      "ca9461589e70: Waiting\n",
      "98d7f5a52dc7: Waiting\n",
      "c701d81a8c64: Pulling fs layer\n",
      "377536e3f3d3: Pulling fs layer\n",
      "be7af55ccd20: Pulling fs layer\n",
      "527ddc9414f3: Pulling fs layer\n",
      "55bd0fd3d326: Waiting\n",
      "c701d81a8c64: Waiting\n",
      "377536e3f3d3: Waiting\n",
      "be7af55ccd20: Waiting\n",
      "527ddc9414f3: Waiting\n",
      "67e3aa572370: Pulling fs layer\n",
      "41d293c79c2d: Pulling fs layer\n",
      "0f1fe48b53c2: Pulling fs layer\n",
      "664a26ac590d: Pulling fs layer\n",
      "9ca0bd2988ae: Pulling fs layer\n",
      "67e3aa572370: Waiting\n",
      "41d293c79c2d: Waiting\n",
      "0f1fe48b53c2: Waiting\n",
      "664a26ac590d: Waiting\n",
      "32248d83cc01: Pulling fs layer\n",
      "51b8d132ed48: Pulling fs layer\n",
      "acf691f01dfd: Pulling fs layer\n",
      "9ca0bd2988ae: Waiting\n",
      "32248d83cc01: Waiting\n",
      "51b8d132ed48: Waiting\n",
      "acf691f01dfd: Waiting\n",
      "981ae4862c05: Download complete\n",
      "5bad8949dcb1: Verifying Checksum\n",
      "5bad8949dcb1: Download complete\n",
      "ca9461589e70: Verifying Checksum\n",
      "ca9461589e70: Download complete\n",
      "6aa38bd67045: Verifying Checksum\n",
      "6aa38bd67045: Download complete\n",
      "55bd0fd3d326: Verifying Checksum\n",
      "55bd0fd3d326: Download complete\n",
      "c701d81a8c64: Verifying Checksum\n",
      "c701d81a8c64: Download complete\n",
      "98d7f5a52dc7: Verifying Checksum\n",
      "98d7f5a52dc7: Download complete\n",
      "377536e3f3d3: Verifying Checksum\n",
      "377536e3f3d3: Download complete\n",
      "527ddc9414f3: Verifying Checksum\n",
      "527ddc9414f3: Download complete\n",
      "41d293c79c2d: Verifying Checksum\n",
      "41d293c79c2d: Download complete\n",
      "67e3aa572370: Verifying Checksum\n",
      "67e3aa572370: Download complete\n",
      "be7af55ccd20: Verifying Checksum\n",
      "be7af55ccd20: Download complete\n",
      "0f1fe48b53c2: Verifying Checksum\n",
      "0f1fe48b53c2: Download complete\n",
      "664a26ac590d: Verifying Checksum\n",
      "664a26ac590d: Download complete\n",
      "32248d83cc01: Verifying Checksum\n",
      "32248d83cc01: Download complete\n",
      "9ca0bd2988ae: Verifying Checksum\n",
      "9ca0bd2988ae: Download complete\n",
      "acf691f01dfd: Verifying Checksum\n",
      "acf691f01dfd: Download complete\n",
      "51b8d132ed48: Verifying Checksum\n",
      "51b8d132ed48: Download complete\n",
      "6aa38bd67045: Pull complete\n",
      "981ae4862c05: Pull complete\n",
      "5bad8949dcb1: Pull complete\n",
      "ca9461589e70: Pull complete\n",
      "98d7f5a52dc7: Pull complete\n",
      "55bd0fd3d326: Pull complete\n",
      "c701d81a8c64: Pull complete\n",
      "377536e3f3d3: Pull complete\n",
      "be7af55ccd20: Pull complete\n",
      "527ddc9414f3: Pull complete\n",
      "67e3aa572370: Pull complete\n",
      "41d293c79c2d: Pull complete\n",
      "0f1fe48b53c2: Pull complete\n",
      "664a26ac590d: Pull complete\n",
      "9ca0bd2988ae: Pull complete\n",
      "32248d83cc01: Pull complete\n",
      "51b8d132ed48: Pull complete\n",
      "acf691f01dfd: Pull complete\n",
      "Digest: sha256:20355426e894145694dfc52c21ebe4b136985705d154d978616c44aa6a3b8e4d\n",
      "Status: Downloaded newer image for 9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io/azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d:latest\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt\n",
      "===============================================================================================================\n",
      "[2020-08-17T21:55:36.463948] Entering job preparation.\n",
      "[2020-08-17T21:55:37.065417] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:37.065463] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:37.067326] Starting job preparation.\n",
      "[2020-08-17T21:55:37.067352] Extracting the control code.\n",
      "[2020-08-17T21:55:37.097322] fetching and extracting the control code on master node.\n",
      "[2020-08-17T21:55:37.097360] Starting extract_project.\n",
      "[2020-08-17T21:55:37.097484] Starting to extract zip file.\n",
      "[2020-08-17T21:55:37.856535] Finished extracting zip file.\n",
      "[2020-08-17T21:55:38.008661] Using urllib.request Python 3.0 or later\n",
      "[2020-08-17T21:55:38.008773] Start fetching snapshots.\n",
      "[2020-08-17T21:55:38.008837] Start fetching snapshot.\n",
      "[2020-08-17T21:55:38.008853] Retrieving project from snapshot: 4657fa78-310a-428f-9559-7195ea2c8f7a\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 53\n",
      "[2020-08-17T21:55:38.010019] Start RetrieveProjectSasUrls\n",
      "[2020-08-17T21:55:38.660938] Finished RetrieveProjectSasUrls\n",
      "[2020-08-17T21:55:38.661018] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:38.661032] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:38.662322] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:38.662374] Starting project file download.\n",
      "[2020-08-17T21:55:38.662425] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:38.662502] _download_tree start request for file\n",
      "[2020-08-17T21:55:38.810454] _download_tree finished request for file\n",
      "[2020-08-17T21:55:38.810528] _download_tree start writing file\n",
      "[2020-08-17T21:55:38.810551] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:38.810566] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:38.877589] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:38.877643] _download_tree finished writing file\n",
      "[2020-08-17T21:55:38.877702] Finished project file download.\n",
      "[2020-08-17T21:55:38.877734] Finished fetching snapshot.\n",
      "[2020-08-17T21:55:38.877746] Start fetching snapshot.\n",
      "[2020-08-17T21:55:38.877760] Retrieving project from snapshot: 883496a5-da95-4c8b-9058-3bfbbbfedf17\n",
      "[2020-08-17T21:55:38.877960] Start RetrieveProjectSasUrls\n",
      "[2020-08-17T21:55:39.418092] Finished RetrieveProjectSasUrls\n",
      "[2020-08-17T21:55:39.418197] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:39.418231] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:39.421117] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:39.421205] Starting project file download.\n",
      "[2020-08-17T21:55:39.486680] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:39.486809] _download_tree start request for file\n",
      "[2020-08-17T21:55:39.682356] _download_tree finished request for file\n",
      "[2020-08-17T21:55:39.682412] _download_tree start writing file\n",
      "[2020-08-17T21:55:39.682435] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:39.682451] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:39.749610] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:39.749650] _download_tree finished writing file\n",
      "[2020-08-17T21:55:39.749683] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:39.749798] _download_tree start request for file\n",
      "[2020-08-17T21:55:39.773052] _download_tree finished request for file\n",
      "[2020-08-17T21:55:39.773081] _download_tree start writing file\n",
      "[2020-08-17T21:55:39.773091] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:39.773107] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:39.788121] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:39.788175] _download_tree finished writing file\n",
      "[2020-08-17T21:55:39.834417] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:39.834571] _download_tree start request for file\n",
      "[2020-08-17T21:55:39.854561] _download_tree finished request for file\n",
      "[2020-08-17T21:55:39.854588] _download_tree start writing file\n",
      "[2020-08-17T21:55:39.854617] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:39.854642] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:39.871326] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:39.871369] _download_tree finished writing file\n",
      "[2020-08-17T21:55:39.871402] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:39.871497] _download_tree start request for file\n",
      "[2020-08-17T21:55:39.909915] _download_tree finished request for file\n",
      "[2020-08-17T21:55:39.909946] _download_tree start writing file\n",
      "[2020-08-17T21:55:39.910050] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:39.910074] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:39.927399] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:39.927711] _download_tree finished writing file\n",
      "[2020-08-17T21:55:39.927737] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:39.927934] _download_tree start request for file\n",
      "[2020-08-17T21:55:39.949718] _download_tree finished request for file\n",
      "[2020-08-17T21:55:39.949745] _download_tree start writing file\n",
      "[2020-08-17T21:55:39.949754] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:39.949763] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.013625] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.013722] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.013784] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.013917] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.035072] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.035102] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.035115] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.035132] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.050406] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.050448] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.050480] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.050719] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.073536] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.073568] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.073579] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.073589] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.088202] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.088234] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.088260] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.088377] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.107149] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.107177] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.107186] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.107201] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.123259] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.123307] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.123354] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.123430] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.144156] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.144186] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.144196] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.144211] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.162631] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.162684] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.162736] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.162813] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.183203] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.183229] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.183237] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.183245] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.199031] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.199061] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.199152] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.199504] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.220369] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.220396] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.220416] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.220628] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.237336] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.237367] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.237435] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.237566] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.257092] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.257118] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.257125] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.257134] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.321579] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.321621] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.321680] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.321771] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.342849] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.342880] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.342898] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.342913] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.357287] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.357315] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.357336] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.357420] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.378443] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.378489] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.378521] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.378552] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.442615] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.442651] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.442677] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.442890] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.479978] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.480007] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.480016] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.480025] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.494638] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.494670] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.494694] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.494767] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.516882] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.516911] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.516923] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.516953] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.532868] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.532896] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.532921] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.533119] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.553099] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.553129] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.553140] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.553155] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.569550] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.569594] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.569693] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.570005] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.590389] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.590415] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.590444] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.590452] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.653970] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.654015] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.654093] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.654306] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.674835] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.674877] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.674903] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.674985] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.694589] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.694633] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.694659] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.694817] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.715436] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.715512] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.715521] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.715528] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.778675] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.778757] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.778809] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.779131] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.801239] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.801265] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.801274] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.801283] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.817079] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.817149] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.817197] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.817286] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.837092] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.837119] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.837129] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.837138] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.852549] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.852581] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.852631] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.852784] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.872962] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.872991] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.873001] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.873016] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.936579] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.936627] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.936688] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.936947] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.956772] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.956799] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.956809] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.956830] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:40.973694] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:40.973727] _download_tree finished writing file\n",
      "[2020-08-17T21:55:40.973752] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:40.973874] _download_tree start request for file\n",
      "[2020-08-17T21:55:40.994519] _download_tree finished request for file\n",
      "[2020-08-17T21:55:40.994545] _download_tree start writing file\n",
      "[2020-08-17T21:55:40.994555] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:40.994569] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.009118] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.009163] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.009187] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.009260] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.030498] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.030527] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.030536] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.030545] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.098111] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.098164] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.098199] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.098334] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.118561] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.118588] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.118597] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.118606] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.135794] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.135825] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.135848] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.136269] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.161551] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.161599] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.161609] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.161622] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.177892] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.177956] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.177978] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.178120] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.197601] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.197629] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.197639] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.197650] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.212495] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.212530] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.212559] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.212665] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.231126] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.231151] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.231159] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.231220] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.309692] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.309732] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.309775] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.309867] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.330403] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.330450] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.330476] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.330493] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.347126] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.347154] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.347175] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.347353] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.366489] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.366516] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.366557] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.366600] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.431871] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.431932] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.431962] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.432116] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.453349] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.453377] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.453452] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.453479] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.469222] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.469255] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.469301] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.469471] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.490161] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.490189] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.490199] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.490207] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.506214] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.506245] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.506283] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.506484] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.528039] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.528066] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.528086] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.528103] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.592467] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.592505] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.592571] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.592826] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.612857] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.612884] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.612896] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.612910] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.677367] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.677403] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.677429] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.677578] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.697867] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.697895] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.697905] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.697922] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.713880] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.713910] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.713955] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.714193] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.734854] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.734882] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.734891] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.734923] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.750409] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.750456] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.750484] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.750556] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.770900] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.770928] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.770936] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.770944] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.801018] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.801067] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.801090] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.801159] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.820408] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.820448] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.820476] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.820484] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.835434] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.835463] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.835507] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.835662] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.856886] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.856941] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.856949] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.856979] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:41.922067] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:41.922102] _download_tree finished writing file\n",
      "[2020-08-17T21:55:41.922130] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:41.922248] _download_tree start request for file\n",
      "[2020-08-17T21:55:41.942633] _download_tree finished request for file\n",
      "[2020-08-17T21:55:41.942662] _download_tree start writing file\n",
      "[2020-08-17T21:55:41.942688] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:41.942719] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:42.006947] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:42.007016] _download_tree finished writing file\n",
      "[2020-08-17T21:55:42.007052] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:42.007140] _download_tree start request for file\n",
      "[2020-08-17T21:55:42.027227] _download_tree finished request for file\n",
      "[2020-08-17T21:55:42.027252] _download_tree start writing file\n",
      "[2020-08-17T21:55:42.027261] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:42.027269] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:42.041700] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:42.041730] _download_tree finished writing file\n",
      "[2020-08-17T21:55:42.041872] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:42.042026] _download_tree start request for file\n",
      "[2020-08-17T21:55:42.061018] _download_tree finished request for file\n",
      "[2020-08-17T21:55:42.061046] _download_tree start writing file\n",
      "[2020-08-17T21:55:42.061075] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:42.061084] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:42.123806] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:42.123863] _download_tree finished writing file\n",
      "[2020-08-17T21:55:42.123926] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:42.124081] _download_tree start request for file\n",
      "[2020-08-17T21:55:42.195600] _download_tree finished request for file\n",
      "[2020-08-17T21:55:42.195633] _download_tree start writing file\n",
      "[2020-08-17T21:55:42.195642] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:42.195666] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:45.760435] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:45.760543] _download_tree finished writing file\n",
      "[2020-08-17T21:55:45.760581] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:45.761290] _download_tree start request for file\n",
      "[2020-08-17T21:55:45.780961] _download_tree finished request for file\n",
      "[2020-08-17T21:55:45.780986] _download_tree start writing file\n",
      "[2020-08-17T21:55:45.781012] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:45.781025] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:45.795890] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:45.795927] _download_tree finished writing file\n",
      "[2020-08-17T21:55:45.795955] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:45.796033] _download_tree start request for file\n",
      "[2020-08-17T21:55:45.840646] _download_tree finished request for file\n",
      "[2020-08-17T21:55:45.840673] _download_tree start writing file\n",
      "[2020-08-17T21:55:45.840899] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:45.840925] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:45.856272] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:45.856300] _download_tree finished writing file\n",
      "[2020-08-17T21:55:45.856321] Starting _download_tree for file.\n",
      "[2020-08-17T21:55:45.856516] _download_tree start request for file\n",
      "[2020-08-17T21:55:45.877551] _download_tree finished request for file\n",
      "[2020-08-17T21:55:45.877582] _download_tree start writing file\n",
      "[2020-08-17T21:55:45.877610] TimeoutHandler __init__\n",
      "[2020-08-17T21:55:45.877620] TimeoutHandler __enter__\n",
      "[2020-08-17T21:55:45.892804] TimeoutHandler __exit__\n",
      "[2020-08-17T21:55:45.892851] _download_tree finished writing file\n",
      "[2020-08-17T21:55:45.892950] Finished project file download.\n",
      "[2020-08-17T21:55:45.893050] Finished fetching snapshot.\n",
      "[2020-08-17T21:55:45.893070] Finished fetching snapshots.\n",
      "[2020-08-17T21:55:45.893099] Finished extract_project.\n",
      "[2020-08-17T21:55:45.907786] Finished fetching and extracting the control code.\n",
      "[2020-08-17T21:55:45.910933] downloadDataStore - Download from datastores if requested.\n",
      "[2020-08-17T21:55:45.911842] Start run_history_prep.\n",
      "[2020-08-17T21:55:45.962794] Entering context manager injector.\n",
      "Acquired lockfile /tmp/50eb4267-4f7b-415f-9a22-dea8aab740cd-datastore.lock to downloading input data references\n",
      "[2020-08-17T21:55:47.343155] downloadDataStore completed\n",
      "[2020-08-17T21:55:47.347015] Job preparation is complete.\n",
      "[2020-08-17T21:55:47.347368] TimeoutHandler __exit__\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "[2020-08-17T21:55:48.698149] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.12.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '10', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/inferences', '--input_fds_0', 'diabetes_batch', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/batch-data/'])\n",
      "Initialize DatasetContextManager.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 113\n",
      "Set Dataset diabetes_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/419afaca-1eb3-4691-9bcc-650b452951a2\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.12.0.post1 azureml-dataprep==2.0.6. Session id: d035eb11-2abe-49c9-8d2a-c4ece8ebc1be. Run id: 50eb4267-4f7b-415f-9a22-dea8aab740cd.\n",
      "Processing 'diabetes_batch'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'batch-data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"fa9cb87f-c509-4b8c-9231-ef830366ddae\",\n",
      "    \"name\": \"batch-data\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"batch data\",\n",
      "    \"workspace\": \"Workspace.create(name='workspace', subscription_id='84170def-2683-47c0-91ed-1f34057afd69', resource_group='resources')\"\n",
      "  }\n",
      "}\n",
      "Mounted diabetes_batch to /mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/batch-data/\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Entering Run History Context Manager.\n",
      "Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd\n",
      "Preparing to call script [ driver/amlbi_main.py ] with arguments: ['--client_sdk_version', '1.12.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '10', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/inferences', '--input_fds_0', 'diabetes_batch', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/batch-data/']\n",
      "After variable expansion, calling script [ driver/amlbi_main.py ] with arguments: ['--client_sdk_version', '1.12.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '10', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/inferences', '--input_fds_0', 'diabetes_batch', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/mounts/workspaceblobstore/batch-data/']\n",
      "\n",
      "Script type = None\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-08-17T21:56:31.690739\n",
      "Starting job release. Current time:2020-08-17T21:56:32.721002\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 473\n",
      "[2020-08-17T21:56:32.740177] Entering context manager injector.\n",
      "Job release is complete. Current time:2020-08-17T21:56:33.627518\n",
      "\n",
      "StepRun(batch-score-diabetes) Execution Summary\n",
      "================================================\n",
      "StepRun( batch-score-diabetes ) Status: Finished\n",
      "{'runId': '50eb4267-4f7b-415f-9a22-dea8aab740cd', 'target': 'susumu-cluster', 'status': 'Completed', 'startTimeUtc': '2020-08-17T21:54:08.69952Z', 'endTimeUtc': '2020-08-17T21:56:43.406807Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '4657fa78-310a-428f-9559-7195ea2c8f7a', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '3d93909b-34e6-44f1-8447-e3da061d573f', 'azureml.pipelinerunid': '35a034bd-1ec8-41de-9f4b-fb8cdc067bc0', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'fa9cb87f-c509-4b8c-9231-ef830366ddae'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_batch', 'mechanism': 'Mount', 'pathOnCompute': '419afaca-1eb3-4691-9bcc-650b452951a2'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'scriptType': None, 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.12.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '10', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_inferences', '--input_fds_0', 'diabetes_batch', '--input1', '$AZUREML_DATAREFERENCE_diabetes_batch_0'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'susumu-cluster', 'dataReferences': {'diabetes_batch_0': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'batch-data/', 'pathOnCompute': None, 'overwrite': False}, 'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/50eb4267-4f7b-415f-9a22-dea8aab740cd/inferences', 'pathOnCompute': 'diabetes/results', 'overwrite': False}}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': 'fa9cb87f-c509-4b8c-9231-ef830366ddae', 'name': None, 'version': '1'}, 'dataPath': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': '419afaca-1eb3-4691-9bcc-650b452951a2', 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'batch_environment', 'version': 'Autosave_2020-08-17T21:44:47Z_b3fe0424', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['scikit-learn', 'azureml-defaults', 'azureml-core', 'azureml-dataprep[fuse]']}], 'name': 'azureml_0d2c44fcbf994b7e881cd6e7891c081c'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200723.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=MQRWvSo5GeqI%2FLuL03jPy9KAXB%2FQoPxfF67evr1FETc%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/azureml-logs/55_azureml-execution-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt?sv=2019-02-02&sr=b&sig=Cvmw9qwoq3DLMOJEdagiQzYhvxc10z1bDjQJubw5PTM%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'azureml-logs/65_job_prep-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/azureml-logs/65_job_prep-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt?sv=2019-02-02&sr=b&sig=DW1lKVb6Fe6Nb9esw9gc3cnQqXQ6z4qWLD2KeA%2BVML4%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=gATwkKplzjZcsf6Lh0HzHM0D%2BiKQllhnvdF28B%2F6IsE%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'azureml-logs/75_job_post-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/azureml-logs/75_job_post-tvmps_b522d36091e44fefabe86830f2572fa6276363b58dcb4acdc5249d8f9b2560e7_d.txt?sv=2019-02-02&sr=b&sig=zNAaOuRP05mZTCxBjYVQYYeSG3mZ0%2FCbMHLPZU%2F7nak%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'azureml-logs/process_info.json': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=VtUxGaq2bHUkl5vOqCBkBlCYjWFj1mLXS6cyOB0v%2BHg%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'azureml-logs/process_status.json': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=YcM0OHnPYAeBvadc3lZuytppjBo73TXMlkigzL%2BbWUg%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/113_azureml.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/113_azureml.log?sv=2019-02-02&sr=b&sig=myKgZH6t6HGllF2tnt9UM7OvFPwXE1lpx%2FSJjdjMQA0%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=Z%2FRWzQTml%2Bsd2xjVHJ%2FR5aOHbc20k%2Bz958TtBxhlHvc%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=iybZJnl1cz5g9%2Fs7XRU1oCBy%2BxeDv0QKlctUzW3paz4%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/dataprep/engine_spans_l_2474e460-b731-480c-8ac2-f37a486d1937.jsonl': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/dataprep/engine_spans_l_2474e460-b731-480c-8ac2-f37a486d1937.jsonl?sv=2019-02-02&sr=b&sig=ff%2FVzAKewjjAJ9H7aF3Piem2kGuAQyMc7PSDc0%2BrcwI%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/dataprep/python_span_l_2474e460-b731-480c-8ac2-f37a486d1937.jsonl': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/dataprep/python_span_l_2474e460-b731-480c-8ac2-f37a486d1937.jsonl?sv=2019-02-02&sr=b&sig=v8rox5bY%2BFWnqyf5PQw870tTupom1wPL9IG4Kbg%2BclE%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=Xp6zCBwpXaMEwX3XI%2BQNb6dQkpTzoYL5tG1nJvH0dXU%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=GU%2FKuXppJZ%2FYOGAGiGtCHLP2ikm3yBd50ESNUbVPZgU%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=d0SrQdMXDx5L%2FuL2W5XnEb8OcKpi8aEbJC%2FB5TzRtAY%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Ethewwlib5bI5LAew1rkUtHmR41J9P6g%2FpKLyuWoH2M%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.50eb4267-4f7b-415f-9a22-dea8aab740cd/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=z1MGhFlV4DJywKhkmO9VfgUQ0ZToaPSL%2B%2Bv%2FPgtFKfo%3D&st=2020-08-17T21%3A46%3A39Z&se=2020-08-18T05%3A56%3A39Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '35a034bd-1ec8-41de-9f4b-fb8cdc067bc0', 'status': 'Completed', 'startTimeUtc': '2020-08-17T21:43:45.750318Z', 'endTimeUtc': '2020-08-17T21:56:46.155072Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.35a034bd-1ec8-41de-9f4b-fb8cdc067bc0/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=%2F8J%2Foqz0g9rDEXecrpz%2FCKq%2FSgzi30Eg4XpfwfPMkCk%3D&st=2020-08-17T21%3A35%3A07Z&se=2020-08-18T05%3A45%3A07Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.35a034bd-1ec8-41de-9f4b-fb8cdc067bc0/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=TiwNrfJpRqY2%2B2kuOc%2FNULsN88UPUF3XUj4vMTtryQI%3D&st=2020-08-17T21%3A35%3A07Z&se=2020-08-18T05%3A45%3A07Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.35a034bd-1ec8-41de-9f4b-fb8cdc067bc0/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=qFZCRBUjsneGpXBV7PYozEU8rOy1uJ%2Bchz7kHDgBWrE%3D&st=2020-08-17T21%3A35%3A07Z&se=2020-08-18T05%3A45%3A07Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pipeline.core.Pipeline(ws, [parallel_run_step])\n",
    "pipeline_run = core.Experiment(ws, 'batch_prediction_pipeline').submit(p)\n",
    "print('Running pipeline...')\n",
    "pipeline_run.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the pipeline has finished running, the resulting predictions will have been saved in the outputs of the experiment associated with the first (and only) step in the pipeline. You can retrieve it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>57.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>59.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>61.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      File  Prediction\n",
       "0   45.csv           0\n",
       "1   46.csv           1\n",
       "2   47.csv           1\n",
       "3   48.csv           1\n",
       "4   49.csv           0\n",
       "5    5.csv           0\n",
       "6   50.csv           1\n",
       "7   51.csv           0\n",
       "8   52.csv           0\n",
       "9   53.csv           1\n",
       "10  54.csv           0\n",
       "11  55.csv           0\n",
       "12  56.csv           0\n",
       "13  57.csv           1\n",
       "14  58.csv           0\n",
       "15  59.csv           0\n",
       "16   6.csv           0\n",
       "17  60.csv           0\n",
       "18  61.csv           0\n",
       "19  62.csv           1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
    "\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "result_file = None\n",
    "for root, dirs, files in os.walk('diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Pipeline and use its REST Interface\n",
    "\n",
    "Now that you have a working pipeline for batch inferencing, you can publish it and use a REST endpoint to run it from an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Diabetes_Parallel_Batch_Pipeline</td><td><a href=\"https://ml.azure.com/pipelines/5810608f-0e6c-4de6-ad61-1fb4c5ff4550?wsid=/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourcegroups/resources/workspaces/workspace\" target=\"_blank\" rel=\"noopener\">5810608f-0e6c-4de6-ad61-1fb4c5ff4550</a></td><td>Active</td><td><a href=\"https://brazilsouth.api.azureml.ms/pipelines/v1.0/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourceGroups/resources/providers/Microsoft.MachineLearningServices/workspaces/workspace/PipelineRuns/PipelineSubmit/5810608f-0e6c-4de6-ad61-1fb4c5ff4550\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: Diabetes_Parallel_Batch_Pipeline,\n",
       "Id: 5810608f-0e6c-4de6-ad61-1fb4c5ff4550,\n",
       "Status: Active,\n",
       "Endpoint: https://brazilsouth.api.azureml.ms/pipelines/v1.0/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourceGroups/resources/providers/Microsoft.MachineLearningServices/workspaces/workspace/PipelineRuns/PipelineSubmit/5810608f-0e6c-4de6-ad61-1fb4c5ff4550)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name='Diabetes_Parallel_Batch_Pipeline', \n",
    "    description='Batch scoring of diabetes data', version='1.0'\n",
    ")\n",
    "\n",
    "published_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the published pipeline has an endpoint, which you can see in the Azure portal. You can also find it as a property of the published pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://brazilsouth.api.azureml.ms/pipelines/v1.0/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourceGroups/resources/providers/Microsoft.MachineLearningServices/workspaces/workspace/PipelineRuns/PipelineSubmit/5810608f-0e6c-4de6-ad61-1fb4c5ff4550\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:\n",
    "\n",
    "> **Note**: A real application would require a service principal with which to be authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "source": [
    "interactive_auth = authentication.InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print('Authentication header ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b26daa70-a736-4098-a070-2e913b60d0aa'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(\n",
    "    rest_endpoint,\n",
    "    json={\"ExperimentName\": \"Batch_Pipeline_via_REST\"},\n",
    "    headers=auth_header,\n",
    ")\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the run ID, we can view the experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline...\n",
      "PipelineRunId: b26daa70-a736-4098-a070-2e913b60d0aa\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Batch_Pipeline_via_REST/runs/b26daa70-a736-4098-a070-2e913b60d0aa?wsid=/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourcegroups/resources/workspaces/workspace\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 40f90548-d872-409e-8eae-21b50b1c90ff\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Batch_Pipeline_via_REST/runs/40f90548-d872-409e-8eae-21b50b1c90ff?wsid=/subscriptions/84170def-2683-47c0-91ed-1f34057afd69/resourcegroups/resources/workspaces/workspace\n",
      "StepRun( batch-score-diabetes ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt\n",
      "========================================================================================================================\n",
      "2020-08-17T22:32:13Z Starting output-watcher...\n",
      "2020-08-17T22:32:13Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-08-17T22:32:15Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2020-08-17T22:32:15Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d\n",
      "6aa38bd67045: Pulling fs layer\n",
      "981ae4862c05: Pulling fs layer\n",
      "5bad8949dcb1: Pulling fs layer\n",
      "ca9461589e70: Pulling fs layer\n",
      "98d7f5a52dc7: Pulling fs layer\n",
      "55bd0fd3d326: Pulling fs layer\n",
      "c701d81a8c64: Pulling fs layer\n",
      "377536e3f3d3: Pulling fs layer\n",
      "be7af55ccd20: Pulling fs layer\n",
      "527ddc9414f3: Pulling fs layer\n",
      "67e3aa572370: Pulling fs layer\n",
      "41d293c79c2d: Pulling fs layer\n",
      "0f1fe48b53c2: Pulling fs layer\n",
      "664a26ac590d: Pulling fs layer\n",
      "9ca0bd2988ae: Pulling fs layer\n",
      "32248d83cc01: Pulling fs layer\n",
      "51b8d132ed48: Pulling fs layer\n",
      "acf691f01dfd: Pulling fs layer\n",
      "ca9461589e70: Waiting\n",
      "98d7f5a52dc7: Waiting\n",
      "55bd0fd3d326: Waiting\n",
      "527ddc9414f3: Waiting\n",
      "c701d81a8c64: Waiting\n",
      "67e3aa572370: Waiting\n",
      "377536e3f3d3: Waiting\n",
      "41d293c79c2d: Waiting\n",
      "be7af55ccd20: Waiting\n",
      "0f1fe48b53c2: Waiting\n",
      "664a26ac590d: Waiting\n",
      "51b8d132ed48: Waiting\n",
      "9ca0bd2988ae: Waiting\n",
      "acf691f01dfd: Waiting\n",
      "32248d83cc01: Waiting\n",
      "981ae4862c05: Verifying Checksum\n",
      "981ae4862c05: Download complete\n",
      "5bad8949dcb1: Download complete\n",
      "ca9461589e70: Verifying Checksum\n",
      "ca9461589e70: Download complete\n",
      "6aa38bd67045: Verifying Checksum\n",
      "6aa38bd67045: Download complete\n",
      "55bd0fd3d326: Verifying Checksum\n",
      "55bd0fd3d326: Download complete\n",
      "c701d81a8c64: Verifying Checksum\n",
      "c701d81a8c64: Download complete\n",
      "98d7f5a52dc7: Verifying Checksum\n",
      "98d7f5a52dc7: Download complete\n",
      "527ddc9414f3: Verifying Checksum\n",
      "527ddc9414f3: Download complete\n",
      "377536e3f3d3: Verifying Checksum\n",
      "377536e3f3d3: Download complete\n",
      "67e3aa572370: Verifying Checksum\n",
      "67e3aa572370: Download complete\n",
      "41d293c79c2d: Verifying Checksum\n",
      "41d293c79c2d: Download complete\n",
      "be7af55ccd20: Verifying Checksum\n",
      "be7af55ccd20: Download complete\n",
      "664a26ac590d: Verifying Checksum\n",
      "664a26ac590d: Download complete\n",
      "0f1fe48b53c2: Verifying Checksum\n",
      "0f1fe48b53c2: Download complete\n",
      "9ca0bd2988ae: Verifying Checksum\n",
      "9ca0bd2988ae: Download complete\n",
      "32248d83cc01: Verifying Checksum\n",
      "32248d83cc01: Download complete\n",
      "acf691f01dfd: Verifying Checksum\n",
      "acf691f01dfd: Download complete\n",
      "51b8d132ed48: Verifying Checksum\n",
      "51b8d132ed48: Download complete\n",
      "6aa38bd67045: Pull complete\n",
      "981ae4862c05: Pull complete\n",
      "5bad8949dcb1: Pull complete\n",
      "ca9461589e70: Pull complete\n",
      "98d7f5a52dc7: Pull complete\n",
      "55bd0fd3d326: Pull complete\n",
      "c701d81a8c64: Pull complete\n",
      "377536e3f3d3: Pull complete\n",
      "be7af55ccd20: Pull complete\n",
      "527ddc9414f3: Pull complete\n",
      "67e3aa572370: Pull complete\n",
      "41d293c79c2d: Pull complete\n",
      "0f1fe48b53c2: Pull complete\n",
      "664a26ac590d: Pull complete\n",
      "9ca0bd2988ae: Pull complete\n",
      "32248d83cc01: Pull complete\n",
      "51b8d132ed48: Pull complete\n",
      "acf691f01dfd: Pull complete\n",
      "Digest: sha256:20355426e894145694dfc52c21ebe4b136985705d154d978616c44aa6a3b8e4d\n",
      "Status: Downloaded newer image for 9c7fb7c2411f4b22b0f89a8ab7233042.azurecr.io/azureml/azureml_9a28c927b28b1c60f87ddcb97fc7490d:latest\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt\n",
      "===============================================================================================================\n",
      "[2020-08-17T22:33:38.334831] Entering job preparation.\n",
      "[2020-08-17T22:33:38.961520] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:38.961559] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:38.962791] Starting job preparation.\n",
      "[2020-08-17T22:33:38.962817] Extracting the control code.\n",
      "[2020-08-17T22:33:39.010987] fetching and extracting the control code on master node.\n",
      "[2020-08-17T22:33:39.011020] Starting extract_project.\n",
      "[2020-08-17T22:33:39.011056] Starting to extract zip file.\n",
      "[2020-08-17T22:33:39.817852] Finished extracting zip file.\n",
      "[2020-08-17T22:33:39.973922] Using urllib.request Python 3.0 or later\n",
      "[2020-08-17T22:33:39.973967] Start fetching snapshots.\n",
      "[2020-08-17T22:33:39.974003] Start fetching snapshot.\n",
      "[2020-08-17T22:33:39.974022] Retrieving project from snapshot: 4657fa78-310a-428f-9559-7195ea2c8f7a\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 51\n",
      "[2020-08-17T22:33:39.974982] Start RetrieveProjectSasUrls\n",
      "[2020-08-17T22:33:40.381777] Finished RetrieveProjectSasUrls\n",
      "[2020-08-17T22:33:40.381850] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:40.381864] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:40.383194] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:40.383233] Starting project file download.\n",
      "[2020-08-17T22:33:40.383710] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:40.383827] _download_tree start request for file\n",
      "[2020-08-17T22:33:40.406578] _download_tree finished request for file\n",
      "[2020-08-17T22:33:40.406607] _download_tree start writing file\n",
      "[2020-08-17T22:33:40.406622] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:40.406636] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:40.471072] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:40.471103] _download_tree finished writing file\n",
      "[2020-08-17T22:33:40.471134] Finished project file download.\n",
      "[2020-08-17T22:33:40.471164] Finished fetching snapshot.\n",
      "[2020-08-17T22:33:40.471176] Start fetching snapshot.\n",
      "[2020-08-17T22:33:40.471189] Retrieving project from snapshot: 883496a5-da95-4c8b-9058-3bfbbbfedf17\n",
      "[2020-08-17T22:33:40.471302] Start RetrieveProjectSasUrls\n",
      "[2020-08-17T22:33:40.553866] Finished RetrieveProjectSasUrls\n",
      "[2020-08-17T22:33:40.554164] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:40.554232] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:40.555665] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:40.555703] Starting project file download.\n",
      "[2020-08-17T22:33:40.628500] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:40.628590] _download_tree start request for file\n",
      "[2020-08-17T22:33:40.792547] _download_tree finished request for file\n",
      "[2020-08-17T22:33:40.792577] _download_tree start writing file\n",
      "[2020-08-17T22:33:40.792586] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:40.792595] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:40.856673] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:40.856709] _download_tree finished writing file\n",
      "[2020-08-17T22:33:40.856768] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:40.856852] _download_tree start request for file\n",
      "[2020-08-17T22:33:40.877869] _download_tree finished request for file\n",
      "[2020-08-17T22:33:40.877900] _download_tree start writing file\n",
      "[2020-08-17T22:33:40.877914] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:40.877929] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:40.901068] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:40.901097] _download_tree finished writing file\n",
      "[2020-08-17T22:33:40.945483] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:40.946021] _download_tree start request for file\n",
      "[2020-08-17T22:33:40.967508] _download_tree finished request for file\n",
      "[2020-08-17T22:33:40.967552] _download_tree start writing file\n",
      "[2020-08-17T22:33:40.967561] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:40.967569] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:40.983698] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:40.983763] _download_tree finished writing file\n",
      "[2020-08-17T22:33:40.983794] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:40.984187] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.006523] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.006551] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.006563] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.006577] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.024099] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.024129] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.024157] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.024572] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.044881] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.044925] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.044935] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.044943] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.112622] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.112652] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.112679] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.112772] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.133811] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.133840] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.133850] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.133858] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.148857] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.148885] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.148911] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.149333] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.170647] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.170676] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.170685] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.170701] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.187730] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.187759] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.187785] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.188128] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.208839] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.208866] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.208875] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.208883] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.225284] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.225316] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.225358] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.225461] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.246856] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.246887] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.246896] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.247023] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.264603] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.264636] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.264730] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.264896] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.287602] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.287630] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.287639] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.287697] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.303454] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.303492] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.303515] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.303662] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.325128] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.325157] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.325166] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.325174] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.340231] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.340285] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.340343] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.340511] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.362380] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.362415] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.362425] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.362433] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.426095] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.426131] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.426158] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.426228] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.448002] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.448031] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.448040] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.448051] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.464648] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.464682] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.464736] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.464836] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.487442] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.487471] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.487480] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.487501] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.551576] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.551608] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.551636] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.551789] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.571419] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.571448] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.571457] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.571465] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.595522] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.595552] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.595596] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.595694] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.618252] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.618281] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.618290] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.618298] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.635213] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.635245] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.635272] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.635345] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.657679] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.657705] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.657714] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.657722] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.675690] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.675731] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.675762] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.675879] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.699538] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.699568] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.699642] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.699676] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.764751] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.764794] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.764911] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.765065] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.787665] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.787694] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.787703] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.787712] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.803255] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.803285] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.803313] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.803690] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.825186] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.825214] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.825230] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.825239] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.889338] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.889383] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.889431] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.889510] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.909685] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.909717] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.909742] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.909751] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.924680] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.924717] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.924778] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.925229] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.944334] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.944367] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.944377] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.944391] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:41.960668] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:41.960753] _download_tree finished writing file\n",
      "[2020-08-17T22:33:41.961158] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:41.961676] _download_tree start request for file\n",
      "[2020-08-17T22:33:41.983949] _download_tree finished request for file\n",
      "[2020-08-17T22:33:41.983980] _download_tree start writing file\n",
      "[2020-08-17T22:33:41.983992] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:41.984007] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.048917] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.048978] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.049010] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.049212] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.068821] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.068848] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.068862] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.068899] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.084046] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.084073] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.084097] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.084452] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.104512] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.104542] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.104565] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.104612] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.122597] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.122627] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.122710] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.123234] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.143797] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.143826] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.143835] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.143843] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.217465] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.217509] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.217579] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.217774] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.238237] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.238268] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.238277] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.238286] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.272171] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.272221] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.272310] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.272647] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.292129] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.292157] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.292166] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.292186] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.308310] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.308344] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.308392] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.308553] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.329578] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.329607] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.329620] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.329635] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.363235] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.363266] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.363291] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.363478] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.385003] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.385031] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.385040] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.385048] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.448913] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.448946] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.449045] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.449237] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.469855] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.469882] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.469894] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.469909] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.485395] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.485432] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.485461] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.485536] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.506642] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.506673] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.506683] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.506699] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.573112] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.573149] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.573195] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.573396] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.592951] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.592980] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.592990] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.593000] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.626474] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.626507] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.626558] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.626739] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.646118] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.646148] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.646164] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.646213] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.662870] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.662903] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.662996] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.663189] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.682220] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.682267] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.682276] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.682284] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.747305] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.747372] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.747404] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.747594] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.767310] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.767341] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.767357] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.767370] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.833006] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.833042] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.833078] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.833264] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.853613] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.853642] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.853651] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.853659] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.869821] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.869853] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.869902] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.870163] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.891230] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.891260] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.891270] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.891302] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.908087] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.908119] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.908177] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.908650] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.928608] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.928637] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.928656] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.928671] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.945296] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.945483] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.945565] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.946086] _download_tree start request for file\n",
      "[2020-08-17T22:33:42.966530] _download_tree finished request for file\n",
      "[2020-08-17T22:33:42.966559] _download_tree start writing file\n",
      "[2020-08-17T22:33:42.966572] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:42.966582] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:42.983458] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:42.983487] _download_tree finished writing file\n",
      "[2020-08-17T22:33:42.983514] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:42.983840] _download_tree start request for file\n",
      "[2020-08-17T22:33:43.004419] _download_tree finished request for file\n",
      "[2020-08-17T22:33:43.004448] _download_tree start writing file\n",
      "[2020-08-17T22:33:43.004457] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:43.004468] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:43.068679] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:43.068717] _download_tree finished writing file\n",
      "[2020-08-17T22:33:43.068765] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:43.069146] _download_tree start request for file\n",
      "[2020-08-17T22:33:43.088534] _download_tree finished request for file\n",
      "[2020-08-17T22:33:43.088562] _download_tree start writing file\n",
      "[2020-08-17T22:33:43.088571] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:43.088585] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:43.153295] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:43.153326] _download_tree finished writing file\n",
      "[2020-08-17T22:33:43.153353] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:43.153842] _download_tree start request for file\n",
      "[2020-08-17T22:33:43.297499] _download_tree finished request for file\n",
      "[2020-08-17T22:33:43.297528] _download_tree start writing file\n",
      "[2020-08-17T22:33:43.297537] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:43.297545] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:43.313136] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:43.313167] _download_tree finished writing file\n",
      "[2020-08-17T22:33:43.313245] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:43.313653] _download_tree start request for file\n",
      "[2020-08-17T22:33:43.333384] _download_tree finished request for file\n",
      "[2020-08-17T22:33:43.333412] _download_tree start writing file\n",
      "[2020-08-17T22:33:43.333421] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:43.333435] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:43.396234] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:43.396402] _download_tree finished writing file\n",
      "[2020-08-17T22:33:43.396481] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:43.396820] _download_tree start request for file\n",
      "[2020-08-17T22:33:43.461932] _download_tree finished request for file\n",
      "[2020-08-17T22:33:43.461964] _download_tree start writing file\n",
      "[2020-08-17T22:33:43.461974] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:43.461983] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:46.713862] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:46.713921] _download_tree finished writing file\n",
      "[2020-08-17T22:33:46.713964] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:46.714576] _download_tree start request for file\n",
      "[2020-08-17T22:33:46.738232] _download_tree finished request for file\n",
      "[2020-08-17T22:33:46.738258] _download_tree start writing file\n",
      "[2020-08-17T22:33:46.738267] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:46.738278] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:46.755722] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:46.755749] _download_tree finished writing file\n",
      "[2020-08-17T22:33:46.755772] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:46.756098] _download_tree start request for file\n",
      "[2020-08-17T22:33:46.778204] _download_tree finished request for file\n",
      "[2020-08-17T22:33:46.778232] _download_tree start writing file\n",
      "[2020-08-17T22:33:46.778241] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:46.778249] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:46.798253] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:46.798286] _download_tree finished writing file\n",
      "[2020-08-17T22:33:46.798309] Starting _download_tree for file.\n",
      "[2020-08-17T22:33:46.798604] _download_tree start request for file\n",
      "[2020-08-17T22:33:46.818677] _download_tree finished request for file\n",
      "[2020-08-17T22:33:46.818704] _download_tree start writing file\n",
      "[2020-08-17T22:33:46.818713] TimeoutHandler __init__\n",
      "[2020-08-17T22:33:46.818726] TimeoutHandler __enter__\n",
      "[2020-08-17T22:33:46.838049] TimeoutHandler __exit__\n",
      "[2020-08-17T22:33:46.838078] _download_tree finished writing file\n",
      "[2020-08-17T22:33:46.838123] Finished project file download.\n",
      "[2020-08-17T22:33:46.838224] Finished fetching snapshot.\n",
      "[2020-08-17T22:33:46.838244] Finished fetching snapshots.\n",
      "[2020-08-17T22:33:46.838254] Finished extract_project.\n",
      "[2020-08-17T22:33:46.853376] Finished fetching and extracting the control code.\n",
      "[2020-08-17T22:33:46.856284] downloadDataStore - Download from datastores if requested.\n",
      "[2020-08-17T22:33:46.857483] Start run_history_prep.\n",
      "[2020-08-17T22:33:46.914234] Entering context manager injector.\n",
      "Acquired lockfile /tmp/40f90548-d872-409e-8eae-21b50b1c90ff-datastore.lock to downloading input data references\n",
      "[2020-08-17T22:33:48.301280] downloadDataStore completed\n",
      "[2020-08-17T22:33:48.304477] Job preparation is complete.\n",
      "[2020-08-17T22:33:48.304659] TimeoutHandler __exit__\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "[2020-08-17T22:33:49.866830] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.12.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '10', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/inferences', '--input_fds_0', 'diabetes_batch', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/batch-data/'])\n",
      "Initialize DatasetContextManager.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 111\n",
      "Set Dataset diabetes_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/419afaca-1eb3-4691-9bcc-650b452951a2\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.12.0.post1 azureml-dataprep==2.0.6. Session id: 335189d3-51d7-4403-ac82-5c864e46846c. Run id: 40f90548-d872-409e-8eae-21b50b1c90ff.\n",
      "Processing 'diabetes_batch'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'batch-data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"fa9cb87f-c509-4b8c-9231-ef830366ddae\",\n",
      "    \"name\": \"batch-data\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"batch data\",\n",
      "    \"workspace\": \"Workspace.create(name='workspace', subscription_id='84170def-2683-47c0-91ed-1f34057afd69', resource_group='resources')\"\n",
      "  }\n",
      "}\n",
      "Mounted diabetes_batch to /mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/batch-data/\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Entering Run History Context Manager.\n",
      "Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/azureml/40f90548-d872-409e-8eae-21b50b1c90ff\n",
      "Preparing to call script [ driver/amlbi_main.py ] with arguments: ['--client_sdk_version', '1.12.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '10', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/inferences', '--input_fds_0', 'diabetes_batch', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/batch-data/']\n",
      "After variable expansion, calling script [ driver/amlbi_main.py ] with arguments: ['--client_sdk_version', '1.12.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '10', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/inferences', '--input_fds_0', 'diabetes_batch', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/workspace/azureml/40f90548-d872-409e-8eae-21b50b1c90ff/mounts/workspaceblobstore/batch-data/']\n",
      "\n",
      "Script type = None\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-08-17T22:34:33.417500\n",
      "Starting job release. Current time:2020-08-17T22:34:34.459674\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 475\n",
      "[2020-08-17T22:34:34.479798] Entering context manager injector.\n",
      "Job release is complete. Current time:2020-08-17T22:34:34.942508\n",
      "\n",
      "StepRun(batch-score-diabetes) Execution Summary\n",
      "================================================\n",
      "StepRun( batch-score-diabetes ) Status: Finished\n",
      "{'runId': '40f90548-d872-409e-8eae-21b50b1c90ff', 'target': 'susumu-cluster', 'status': 'Completed', 'startTimeUtc': '2020-08-17T22:32:09.078782Z', 'endTimeUtc': '2020-08-17T22:34:46.869556Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '4657fa78-310a-428f-9559-7195ea2c8f7a', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '3d93909b-34e6-44f1-8447-e3da061d573f', 'azureml.pipelinerunid': 'b26daa70-a736-4098-a070-2e913b60d0aa', 'azureml.pipelineid': '5810608f-0e6c-4de6-ad61-1fb4c5ff4550', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'fa9cb87f-c509-4b8c-9231-ef830366ddae'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_batch', 'mechanism': 'Mount', 'pathOnCompute': '419afaca-1eb3-4691-9bcc-650b452951a2'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'scriptType': None, 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.12.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '10', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_inferences', '--input_fds_0', 'diabetes_batch', '--input1', '$AZUREML_DATAREFERENCE_diabetes_batch_0'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'susumu-cluster', 'dataReferences': {'diabetes_batch_0': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'batch-data/', 'pathOnCompute': None, 'overwrite': False}, 'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/40f90548-d872-409e-8eae-21b50b1c90ff/inferences', 'pathOnCompute': 'diabetes/results', 'overwrite': False}}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': 'fa9cb87f-c509-4b8c-9231-ef830366ddae', 'name': None, 'version': '1'}, 'dataPath': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': '419afaca-1eb3-4691-9bcc-650b452951a2', 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'batch_environment', 'version': 'Autosave_2020-08-17T21:44:47Z_b3fe0424', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['scikit-learn', 'azureml-defaults', 'azureml-core', 'azureml-dataprep[fuse]']}], 'name': 'azureml_0d2c44fcbf994b7e881cd6e7891c081c'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200723.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/azureml-logs/55_azureml-execution-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt?sv=2019-02-02&sr=b&sig=m0dvRgccBYrLi%2Bd2Bprp63shVanrBuPMSV39sR88etQ%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'azureml-logs/65_job_prep-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/azureml-logs/65_job_prep-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt?sv=2019-02-02&sr=b&sig=on62oX0kseUcwmJTCSDIU9bAUFe%2F2WgIGV3jeGzHnzE%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=9RGcmusvFaHYKNbp2nHPftUoOMHYEQIGkOeQ7nsrP%2Fs%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'azureml-logs/75_job_post-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/azureml-logs/75_job_post-tvmps_8410546b7adf966d2a3b8d06f26b312ab538e8546a1ee55bc59596eba9084c19_d.txt?sv=2019-02-02&sr=b&sig=xPhSa86xnwZ0u87xLcz1Od48AujtkhNq%2FLYHGVlaa9o%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'azureml-logs/process_info.json': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=oQeocK%2BhRLSYLmUN%2BwX7JonembQyTR8MBfJXeJGPet8%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'azureml-logs/process_status.json': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=ijaMrfaxtbFyLvzXuiMVOqYdsscigeenAy8FcWyQhNg%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/111_azureml.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/111_azureml.log?sv=2019-02-02&sr=b&sig=6hXUt%2BxL9sdNyoYcg8N00zcghk4TAbCFZkM9mGkUkDM%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=5iVcDHuqRERO3A9ClzpWCpW%2FOtIQhTX2EQ8%2Bt6QYRvY%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=eDsAudSCLzg%2FwfO4UoKuEAHXqiK%2FNSYDh%2B3QYxRugIo%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/dataprep/engine_spans_l_2217049e-1411-40d6-a78a-e10347312c6a.jsonl': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/dataprep/engine_spans_l_2217049e-1411-40d6-a78a-e10347312c6a.jsonl?sv=2019-02-02&sr=b&sig=Xbhsfy2tc2QCSLJQG0T8%2FJZRFZTWjjNOvoImz50yY64%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/dataprep/python_span_l_2217049e-1411-40d6-a78a-e10347312c6a.jsonl': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/dataprep/python_span_l_2217049e-1411-40d6-a78a-e10347312c6a.jsonl?sv=2019-02-02&sr=b&sig=uRhSvKhe%2BRVdmISnaC4u8PMpxKFE72AMpTZOg63ClBM%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=aDgOf8AyTSBrxwHLrLHUZxQFQgZC9hdeNHqXN6VQT%2Fc%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=4dUyDu%2BUgCkAxcdB5dakBl4uVgreFZFDOxKXHVStmdE%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=YdJtv0cze%2F9nFOV8zGo6LZwDn6uCWJSGyQJpjWF0oFs%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=HwmNLXHELbVcThmdiuhnGSuX4pBLOIHONRZ2Jb04JZU%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.40f90548-d872-409e-8eae-21b50b1c90ff/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=omn7R4s0q%2BnS1QlXCG0kr6B67%2FB0IgjRd%2Bfdv3iNr%2Fs%3D&st=2020-08-17T22%3A24%3A41Z&se=2020-08-18T06%3A34%3A41Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'b26daa70-a736-4098-a070-2e913b60d0aa', 'status': 'Completed', 'startTimeUtc': '2020-08-17T22:28:25.525881Z', 'endTimeUtc': '2020-08-17T22:34:48.825878Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': '5810608f-0e6c-4de6-ad61-1fb4c5ff4550'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.b26daa70-a736-4098-a070-2e913b60d0aa/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=P4Or6WpACg8vkQ1L%2F999Dn4FIyd2fERBFGFWhzIg06Q%3D&st=2020-08-17T22%3A22%3A21Z&se=2020-08-18T06%3A32%3A21Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.b26daa70-a736-4098-a070-2e913b60d0aa/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=YkSU7k3ut9%2FnyCXvjJn88Y9Hopr%2FEC5IjLZ7QQDRjz0%3D&st=2020-08-17T22%3A22%3A21Z&se=2020-08-18T06%3A32%3A21Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://workspace9901294163.blob.core.windows.net/azureml/ExperimentRun/dcid.b26daa70-a736-4098-a070-2e913b60d0aa/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=kLc8tDD%2BF7EZuZ7EnDAzh9bNuwm7Yyo%2B8vUMVRU0pp0%3D&st=2020-08-17T22%3A22%3A21Z&se=2020-08-18T06%3A32%3A21Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_pipeline_run = pipeline.core.run.PipelineRun(\n",
    "    ws.experiments[\"Batch_Pipeline_via_REST\"], run_id\n",
    ")\n",
    "print('Running pipeline...')\n",
    "published_pipeline_run.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the results are in the output of the first pipeline step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       File  Prediction\n",
       "0    18.csv           0\n",
       "1    19.csv           0\n",
       "2     2.csv           0\n",
       "3    20.csv           1\n",
       "4    21.csv           1\n",
       "5    22.csv           1\n",
       "6    23.csv           0\n",
       "7    24.csv           0\n",
       "8    25.csv           1\n",
       "9    26.csv           1\n",
       "10    1.csv           0\n",
       "11   10.csv           1\n",
       "12  100.csv           1\n",
       "13   11.csv           0\n",
       "14   12.csv           1\n",
       "15   13.csv           0\n",
       "16   14.csv           1\n",
       "17   15.csv           0\n",
       "18   16.csv           0\n",
       "19   17.csv           0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"diabetes-results\", ignore_errors=True)\n",
    "\n",
    "prediction_run = next(published_pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data(\"inferences\")\n",
    "prediction_output.download(local_path=\"diabetes-results\")\n",
    "\n",
    "for root, dirs, files in os.walk(\"diabetes-results\"):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a pipeline that can be used to batch process daily patient data.\n",
    "\n",
    "**More Information**: For more details about using pipelines for batch inferencing, see the [How to Run Batch Predictions](https://docs.microsoft.com/azure/machine-learning/how-to-run-batch-predictions) in the Azure Machine Learning documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
