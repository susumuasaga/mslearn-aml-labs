{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Real-Time Inferencing Service\n",
    "\n",
    "You've spent a lot of time in this course training and registering machine learning models. Now it's time to deploy a model as a real-time service that clients can use to get predictions from new data.\n",
    "\n",
    "## Before You Start\n",
    "\n",
    "Before you start this lab, ensure that you have completed the *Create an Azure Machine Learning Workspace* and *Create a Compute Instance* tasks in [Lab 1: Getting Started with Azure Machine Learning](./labdocs/Lab01.md). Then open this notebook in Jupyter on your Compute Instance.\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If you do not have a current authenticated session with your Azure subscription, you'll be prompted to authenticate. Follow the instructions to authenticate using the code provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from azureml import core\n",
    "from sklearn import model_selection, tree, metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from azureml.core import conda_dependencies, webservice\n",
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.11.0 to work with workspace\n"
     ]
    }
   ],
   "source": [
    "ws = core.Workspace.from_config()\n",
    "print(f'Ready to use Azure ML {core.VERSION} to work with {ws.name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Register a Model\n",
    "\n",
    "You'll need a trained model to deploy. Run the cell below to train and register a model that predicts the likelihood of a clinic patient being diabetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: diabetes-training\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8903333333333333\n",
      "AUC: 0.8778421812030448\n",
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "experiment = core.Experiment(workspace=ws, name = 'diabetes-training')\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "diabetes: pd.DataFrame = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "X = diabetes[\n",
    "        [\n",
    "            'Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure',\n",
    "            'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree',\n",
    "            'Age',\n",
    "        ]\n",
    "    ].to_numpy()\n",
    "y = diabetes['Diabetic'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.30, random_state=0\n",
    ")\n",
    "\n",
    "print('Training a decision tree model')\n",
    "model = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', acc)\n",
    "\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = metrics.roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC:', auc)\n",
    "run.log('AUC', auc)\n",
    "\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(\n",
    "    name = 'outputs/' + model_file, path_or_stream = './' + model_file\n",
    ")\n",
    "\n",
    "run.complete()\n",
    "\n",
    "run.register_model(\n",
    "    model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "    tags={'Training context':'Inline Training'},\n",
    "    properties={\n",
    "        'AUC': run.get_metrics()['AUC'],\n",
    "        'Accuracy': run.get_metrics()['Accuracy']\n",
    "    }\n",
    ")\n",
    "\n",
    "print('Model trained and registered.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Model as a Web Service\n",
    "\n",
    "Now you have trained and registered a machine learning model that classifies patients based on the likelihood of them having diabetes. This model could be used in a production environment such as a doctor's surgery where only patients deemed to be at risk need to be subjected to a clinical test for diabetes. To support this scenario, you will deploy the model as a web service.\n",
    "\n",
    "First, let's determine what models you have registered in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 9\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8778421812030448\n",
      "\t Accuracy : 0.8903333333333333\n",
      "\n",
      "\n",
      "diabetes_model version: 8\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "diabetes_model version: 7\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "diabetes_model version: 6\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "diabetes_model version: 5\n",
      "\t Training context : Parameterized SKLearn Estimator\n",
      "\t AUC : 0.8483904671874223\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : Parameterized SKLearn Estimator\n",
      "\t AUC : 0.8483904671874223\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Estimator\n",
      "\t AUC : 0.8484929598487486\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Estimator\n",
      "\t AUC : 0.8483377282451863\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Estimator\n",
      "\t AUC : 0.8483377282451863\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in core.Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, now let's get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version 9\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to deploy. We'll deploy the container a service named **diabetes-service**. The deployment process includes the following steps:\n",
    "\n",
    "1. Define an inference configuration, which includes the scoring and environment files required to load and use the model.\n",
    "2. Define a deployment configuration that defines the execution environment in which the service will be hosted. In this case, an Azure Container Instance.\n",
    "3. Deploy the model as a web service.\n",
    "4. Verify the status of the deployed service.\n",
    "\n",
    "> **More Information**: For more details about model deployment, and options for target execution environments, see the [documentation](https://docs.microsoft.com/en-gb/azure/machine-learning/service/how-to-deploy-and-where).\n",
    "\n",
    "Deployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of **Healthy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..............................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "inference_config = core.model.InferenceConfig(\n",
    "    runtime='python',\n",
    "    source_directory=folder_name,\n",
    "    entry_script='score_diabetes.py',\n",
    "    conda_file='diabetes_env.yml'\n",
    ")\n",
    "\n",
    "deployment_config = webservice.AciWebservice.deploy_configuration(\n",
    "    cpu_cores=1, memory_gb=1\n",
    ")\n",
    "\n",
    "service_name = 'diabetes-service'\n",
    "\n",
    "service = core.model.Model.deploy(\n",
    "    workspace=ws, name=service_name, models=[model], \n",
    "    inference_config=inference_config, deployment_config=deployment_config\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, the deployment has been successful and you can see a status of **Healthy**. If not, you can use the following code to check the status and get the service logs to help you troubleshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-15T22:37:28,394589217+00:00 - gunicorn/run \n",
      "2020-08-15T22:37:28,394915217+00:00 - rsyslog/run \n",
      "2020-08-15T22:37:28,396764817+00:00 - iot-server/run \n",
      "2020-08-15T22:37:28,567318743+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 37\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-08-15T22:37:29,936321349+00:00 - iot-server/finish 1 0\n",
      "2020-08-15T22:37:29,937507749+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-08-15 22:37:30,188 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2020-08-15 22:37:30,188 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2020-08-15 22:37:30,188 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2020-08-15 22:37:30,188 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "2020-08-15 22:37:30,280 | root | INFO | Users's init has completed successfully\n",
      "Users's init has completed successfully\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2020-08-15 22:37:30,282 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2020-08-15 22:37:30,282 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2020-08-15 22:37:30,283 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "Scoring timeout is found from os.environ: 60000 ms\n",
      "2020-08-15 22:37:36,919 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-08-15 22:37:36,920 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [15/Aug/2020:22:37:36 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2020-08-15 22:37:43,882 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-08-15 22:37:43,882 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [15/Aug/2020:22:37:43 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())\n",
    "\n",
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at your workspace in the [Azure web interface](https://ml.azure.com) and view the **Endpoints** page, which shows the deployed services in your workspace.\n",
    "\n",
    "You can also retrieve the names of web services in your workspace by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-service\n"
     ]
    }
   ],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Web Service\n",
    "\n",
    "With the service deployed, now you can consume it from a client application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]\n",
      "diabetic\n"
     ]
    }
   ],
   "source": [
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print (f'Patient: {x_new[0]}')\n",
    "\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "predictions = service.run(input_data=input_json)\n",
    "\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also send multiple patient observations to the service, and get back a prediction for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "x_new = [\n",
    "    [2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "    [0,148,58,11,179,39.19207553,0.160829008,45]\n",
    "]\n",
    "\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "predictions = service.run(input_data=input_json)\n",
    "\n",
    "predicted_classes = json.loads(predictions)\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (f\"Patient {x_new[i]} {predicted_classes[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses the Azure ML SDK to connect to the containerized web service and use it to generate predictions from your diabetes classification model. In production, a model is likely to be consumed by business applications that do not use the Azure ML SDK, but simply make HTTP requests to the web service.\n",
    "\n",
    "Let's determine the URL to which these applications must submit their requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://06907fa4-7154-4421-b14b-9817d7ec617f.westus.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers=headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (f\"Patient {x_new[i]} {predicted_classes[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've deployed your web service as an Azure Container Instance (ACI) service that requires no authentication. This is fine for development and testing, but for production you should consider deploying to an Azure Kubernetes Service (AKS) cluster and enabling authentication. This would require REST requests to include an **Authorization** header.\n",
    "\n",
    "### More Information\n",
    "\n",
    "For more information about publishing a model as a service, see the [documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where)\n",
    "\n",
    "## Clean Up\n",
    "\n",
    "If you've finished exploring, you can delete your service by running the cell below. Then close this notebook and shut down your Compute Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
